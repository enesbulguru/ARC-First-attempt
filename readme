Hello Folks!

The first time I have learned about ARC-AGI competition, it was about 3 weeks before the deadline for submissions. At the time, I was (and still is) unemployed bored man who was mostly interested in AI in a peripheral way. But I really like puzzles and my immediate reaction was "That's shouldn't be too hard". I guess my lack of expertise on the subject combined with inability to code should make this assumption pretty stupid. But in hindsight, I now also think that history of our civilization has great examples of "search of the unknown", and these traits that could be considered as negative in AI space actually served me good. This is the first part of that my journey of creating a solver for ARC puzzles. 

Now, if you are able to code and know about ARC-AGI a bit, you can simply dismiss a lot of the logic created in my code because there is simply no intentionality in it. Like I am creating assumptions but there is no visible reason to comply by them. I would like to provide some explanations below on why it's like that. This can also shed some light about development history.

First, most of the this "lack of intention" is not actually planned. It's just bad code.I have spent first 3-4 days at the start to just talk about the puzzles themselves, about Mr. Francois Chollet (creator of ARC puzzles) and his paper "On the Measure of Intelligence" and in general about how to approach the subject. I guess I should also mention that at this point, I just had a generic idea on how a Neural Network works. I have mostly brainstormed with Claude and GPT with relevant content. But as we all know, these tools hallunicate and can make lots of mistakes while also sounding true. And something like this is particularly dangerous if you are talking about topics that you have very little knowledge. Once these brainstorming sessions were over, I have started asking LLM to write some python functions based on what I have imagined in my mind. But since I was unable to comprehend what these code snippets were actually doing, there was a distinct reality gap. And there was nothing I could do about it because I was not aware how big this gap can be.

And yet, since I didn't know exactly what I was looking for, some of the lack of intention was indeed intentional. After all the brainstorming, I was convinced that for a general ARC solution, program can't know what it was looking for and therefore I don't need to as well. To be more precise, all it needs to know is that there is a relationship between the example pairings that will be useful solving a similar problem. Mr Chollet mentions developer-aware generalization, I guess I was trying to follow that logic. He also says "Note that “developer-aware generalization” accounts for any prior knowledge that the developer of the system has injected into it."(On the Measure of Intelligence; I.3.2	The spectrum of generalization: robustness, flexibility, generality). To my mind this can be interpreted as " you can build a system without any priors by simply finding ways to transform the grid in ways that would be more useful and cheap to calculate and still can find some success". (I guess I should also note that inability to code combined with having no resources except a 7 years old laptop and 20 bucks ChatGPT and Claude plan forces me to be cheap first at any points. That also means I am unable to acces AI API's or run local models to train something so I thought I could aim for a universal one shot solver that don't need to train on data. One might argue that there is no learning in such an approach, that the program search space is enormous or any other reason on why it wouldn't work. Me after 4 months understand how colossal such a thing be and how hard it is to find something like that, but my stupidly brave or bravely stupid past self was not aware of this. But I also still believe such a thing is possible even though I am not sure yet how that would be.)

I have spent most of the those 3 weeks trying to refine this program. The idea in my head can be summarized as:

  1.  Create a multidimensional space: Tile the 2D grid plane with a hexagonal grid, project the hexagonal grid into a bigger multidimentional space.(I was under the assumption that you can tile a plane with Hexagonal Prisms and protect the symmetries, which was wrong)
  2.  Project the input and output grids into the multidimensonal space
  3.  Track the space for symmetries and extract patterns
  4.  Try to apply the same pattern to test puzzle.

I am oversimplicating a lot but this is it. I was imagining using golden ratio like a GPS system for this dimentional space, since it has a clear function, and shows itself everywhere in the universe when a structure is emerging into a more complex one. Now obviously code is just a soup of these already vague ideas. Nevertheless, when I saw that it is able to solve 24 puzzles, I have to say, I was over the moon. In my mind, being able to solve 3% of training data was a big leap because I can't code, haven't spent money on it, able to run in my old laptop and able to produce results in mere seconds. This belief actually led me believing that I have found something important and refining it can produce the holy grail for ARC competition. And it took me a very long time to realize that the evaluation functions I am using to determine success are not actually working correctly so at the end of the day, I guess I have just hallucinated the whole thing :D

But I still find value in this. If nothing else, I have hallucinated just like an LLM and I do mean it. A human hallucination can be defined as a mismatch of sensory perception between an individual's inner world versus outer world, which is not that different from an LLM hallucinating because the weights and biases used for a particular relationship within it's technology does not corresponds with how we perceive that relationship.You could argue that in both cases, we're seeing systems that:

**Have internal representations built from prior experience (training/learning)
**Sometimes produce outputs that don't correspond to consensus reality
**Process information through complex network architectures that we don't fully understand.

Overall, I have really enjoyed trying this, thought I found a way to unify Quantum Theory and Relativity (I still do by the way, but now I only give myself %10 percent chance instead of believing it %100), realized that AI field is something I didn't know I was looking for and something I want to immerse myself with for the rest of my life. So it was fun.

I have created more codes for solving ARC Puzzles and other codes that does different things but inspired by this first solver. You can be surprised how much stuff you can create when you are not aware that your knowledge-base is wrong :D

Thanks for reading,
Enes
